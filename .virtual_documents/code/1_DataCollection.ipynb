





# Import essential libraries for data handling, numerical operations, 
# and web data retrieval
import pandas as pd
import numpy as np
from datetime import datetime
import pandas_datareader as web
import yfinance as yf





# Set random seeds for reproducibility
np.random.seed(42)





# Define date range for the data collection
start_date = datetime(1990, 1, 1)
end_date = datetime(2025, 4, 14)  # Recent date





def fetch_economic_data():
    """
    Fetches economic indicators from FRED and S&P 500 from Yahoo Finance, then saves to CSV.
    """
    indicators = {
        'UNRATE': 'unemployment',                     # Unemployment Rate
        'T10Y2Y': 'yield_spread',                     # 10-Year minus 2-Year Yield Spread
        'INDPRO': 'industrial_prod',                  # Industrial Production Index
        'UMCSENT': 'consumer_conf',                   # Consumer Sentiment Index
        'USSLIND': 'LEI',                             # Leading Economic Index
        'CPIAUCSL': 'CPI',                            # Consumer Price Index
        'GDPC1': 'GDP_Growth',                        # Real GDP (quarterly, will interpolate)
        'RECPROUSM156N': 'recession_probabilities',   # Recession Probabilities
        'FEDFUNDS': 'fed_funds_rate',                 # Federal Funds Effective Rate
        'TWEXB': 'currency_strength',                 # Trade Weighted U.S. Dollar Index
        'HOUST': 'housing_starts',                    # Housing Starts
        'PCEPI': 'personal_consumption_expenses',     # PCE Price Index
        'PPIACO': 'PPI'                               # Producer Price Index
    }

    print(f"Fetching {len(indicators)} economic indicators from FRED...")

    # Fetch macro indicators from FRED
    fred_data = web.DataReader(list(indicators.keys()), 'fred', start_date, end_date)
    fred_data.columns = [indicators[k] for k in indicators.keys()]

    # Interpolate quarterly GDP to daily
    fred_data['GDP_Growth'] = fred_data['GDP_Growth'].interpolate(method='linear')

    # Fetch S&P 500 from Yahoo Finance
    print("Fetching S&P 500 data from Yahoo Finance...")
    sp500 = yf.download('^GSPC', start=start_date, end=end_date, group_by='column')
    sp500.index = sp500.index.normalize()  # Align timestamp to date only (remove time)
    sp500.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in sp500.columns.values]
    sp500 = sp500[['Close_^GSPC']].rename(columns={'Close_^GSPC': 'SP500'})
    


    # Merge on date
    combined = fred_data.join(sp500, how='left')

    # Forward-fill and clean
    combined = combined.ffill().dropna(how='all')

    # Save to CSV
    combined.index.name = 'DATE'
    combined.to_csv('data/economic_indicators.csv')

    print(f"Data collected from {combined.index.min()} to {combined.index.max()}")
    print("Data saved to 'data/economic_indicators.csv'")

    return combined





def main():
    # Call the fetch function to download and save data
    fetch_economic_data()

    # Now load the newly saved CSV
    economic_indicators = pd.read_csv('./data/economic_indicators.csv', 
                                      index_col='DATE', 
                                      parse_dates=True)

    # Display basic information
    print("\nDataset shape:", economic_indicators.shape)
    print("\nFirst 5 rows:")
    print(economic_indicators.head())

if __name__ == "__main__":
    main()

